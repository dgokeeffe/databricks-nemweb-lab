bundle:
  name: nemweb-lab
  databricks_cli_version: ">= 0.283.0"

# Build wheel and copy to artifacts/latest
artifacts:
  nemweb_datasource:
    type: whl
    path: "./databricks-nemweb-lab/src"
    build: "rm -f dist/*.whl && uv build --wheel --out-dir dist && mkdir -p ../artifacts && cp dist/nemweb_datasource-*.whl ../artifacts/"

variables:
  # NEMWEB Lab configuration
  project_name:
    description: "Name of the NEMWEB solution accelerator lab"
    default: "nemweb-lab"

  # Unity Catalog configuration
  catalog:
    description: "Unity Catalog catalog name"
    default: "workspace"

  schema:
    description: "Unity Catalog schema name"
    default: "nemweb_lab"

  # Environment for deployment paths
  environment:
    description: "Deployment environment (dev, staging, prod)"
    default: "dev"

# Include files needed for the lab, exclude build artifacts
sync:
  include:
    - "databricks-nemweb-lab/src/*.py"
    - "databricks-nemweb-lab/src/pipeline/**"
    - "databricks-nemweb-lab/notebooks/**"
    - "databricks-nemweb-lab/solutions/**"
    - "databricks-nemweb-lab/artifacts/**"
  exclude:
    - "databricks-nemweb-lab/src/.venv/**"
    - "databricks-nemweb-lab/src/__pycache__/**"
    - "databricks-nemweb-lab/src/*.egg-info/**"
    - "databricks-nemweb-lab/src/build/**"
    - "databricks-nemweb-lab/src/dist/**"
    - "databricks-nemweb-lab/src/tests/**"
    - "**/.pytest_cache/**"
    - "**/__pycache__/**"

targets:
  dev:
    default: true
    mode: development
    # Uses default profile from ~/.databrickscfg
    # Override with: databricks bundle deploy --profile <profile_name>

  prod:
    mode: production
    # Configure for production workspace before deploying

resources:
  # NEMWEB Lakeflow Declarative Pipeline
  pipelines:
    nemweb_pipeline:
      name: "${var.project_name}-pipeline-${var.environment}"
      serverless: true
      catalog: "${var.catalog}"
      schema: "${var.schema}"
      libraries:
        - file:
            path: "./databricks-nemweb-lab/src/pipeline/nemweb_pipeline.py"
      configuration:
        bundle.sourcePath: ${workspace.file_path}/databricks-nemweb-lab/src

  jobs:
    nemweb_lab_workflow:
      name: "${var.project_name} - Lab Exercises [${var.environment}]"
      tasks:
        - task_key: setup_validation
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/00_setup_and_validation.py
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
              include_current: "false"

        - task_key: custom_source
          depends_on:
            - task_key: setup_validation
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/01_custom_source_exercise.py

        - task_key: lakeflow_pipeline
          depends_on:
            - task_key: custom_source
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/02_lakeflow_pipeline.py

        - task_key: cluster_sizing
          depends_on:
            - task_key: lakeflow_pipeline
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/03a_cluster_sizing_exercise.py

        - task_key: optimization_comparison
          depends_on:
            - task_key: lakeflow_pipeline
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/03b_optimization_comparison.py
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"

    # Pipeline refresh job - triggers the Lakeflow pipeline
    nemweb_pipeline_job:
      name: "${var.project_name} - Pipeline Refresh [${var.environment}]"
      tasks:
        - task_key: refresh_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.nemweb_pipeline.id}

    # Solution workflow for instructors
    nemweb_lab_solutions:
      name: "${var.project_name} - Solutions [${var.environment}]"
      tasks:
        - task_key: setup_validation
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/notebooks/00_setup_and_validation.py
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"
              include_current: "false"

        - task_key: custom_source_solution
          depends_on:
            - task_key: setup_validation
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/solutions/01_custom_source_solution.py

        - task_key: lakeflow_pipeline_solution
          depends_on:
            - task_key: custom_source_solution
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/solutions/02_lakeflow_pipeline_solution.py

        - task_key: optimization_solution
          depends_on:
            - task_key: lakeflow_pipeline_solution
          notebook_task:
            notebook_path: ${workspace.file_path}/databricks-nemweb-lab/solutions/03b_optimization_comparison_solution.py
            base_parameters:
              catalog: "${var.catalog}"
              schema: "${var.schema}"

# For more options and schema, see: https://docs.databricks.com/aws/en/dev-tools/bundles/settings
