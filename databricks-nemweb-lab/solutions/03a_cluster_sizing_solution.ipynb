{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Solution: Exercise 3a - Cluster Right-Sizing Analysis\nThis notebook contains the complete solutions for Exercise 3a.\n## Learning Objectives\n1. Interpret Spark UI metrics (CPU%, memory%, task duration)\n2. Calculate required compute from data volume â†’ partitions â†’ cores\n3. Select appropriate instance types based on workload\n4. Set autoscaling boundaries based on patterns\n5. Estimate DBU costs for different configurations\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Scenario: NEMWEB Production Pipeline\nYou're deploying the NEMWEB pipeline to production. Requirements:\n| Metric | Value |\n|--------|-------|\n| Data volume | 6 months historical + daily incremental |\n| Historical load | ~50-100 MB (260k rows) |\n| Daily incremental | ~1 MB (1,440 rows per region Ã— 5 regions) |\n| SLA | Process within 15 minutes of data availability |\n| Budget | Minimize DBU spend while meeting SLA |\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.1: Workload Analysis\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nimport math\n\n# Workload parameters\nHISTORICAL_ROWS = 260_000\nHISTORICAL_SIZE_MB = 100\nDAILY_ROWS = 7_200  # 288 intervals Ã— 5 regions Ã— 5 (days buffer)\nDAILY_SIZE_MB = 3\n\n# Spark defaults\nDEFAULT_PARTITION_SIZE_MB = 128\nCORES_PER_PARTITION = 1  # One task per core\n\n# SOLUTION 3.1a: Calculate optimal partition count for historical load\n# Formula: partitions = data_size_mb / target_partition_size_mb\n# Target partition size: 64-128 MB for balanced parallelism\n\ntarget_partition_size_mb = 64  # Smaller partitions for better parallelism\nhistorical_partitions = math.ceil(HISTORICAL_SIZE_MB / target_partition_size_mb)\n\nprint(f\"Historical data: {HISTORICAL_SIZE_MB} MB\")\nprint(f\"Target partition size: {target_partition_size_mb} MB\")\nprint(f\"Recommended partitions: {historical_partitions}\")\nprint(f\"\\nNote: With {historical_partitions} partitions, each is ~{HISTORICAL_SIZE_MB/historical_partitions:.0f} MB\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Spark UI Metrics Reference\n| Metric | Target Range | Action if Outside Range |\n|--------|--------------|------------------------|\n| CPU Utilization | 70-80% | <50%: reduce cores; >90%: add cores |\n| Memory Utilization | 60-70% | <40%: use smaller instances; >80%: add memory |\n| Task Duration | 30s-5min | <10s: increase partition size; >10min: add partitions |\n| Shuffle Spill | 0 | Any spill: add memory or reduce partition size |\n| GC Time | <10% of task time | High GC: add memory, check for data skew |\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.2: Core Requirements Calculation\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# Timing requirements\nSLA_MINUTES = 15\nTARGET_COMPLETION_MINUTES = 10  # Leave buffer for variability\n\n# Measured task metrics (from test run)\n# These would come from Spark UI in production\nAVG_TASK_DURATION_SECONDS = 45\nTASK_COUNT = 10  # Number of partitions\n\n# SOLUTION 3.2a: Calculate required parallelism\n# Formula: total_task_time = task_count Ã— avg_task_duration_seconds\n# Required cores = total_task_time / (target_completion_minutes Ã— 60)\n\ntotal_task_time_seconds = TASK_COUNT * AVG_TASK_DURATION_SECONDS\ntarget_time_seconds = TARGET_COMPLETION_MINUTES * 60\nrequired_cores = math.ceil(total_task_time_seconds / target_time_seconds)\n\nprint(f\"Task count: {TASK_COUNT}\")\nprint(f\"Avg task duration: {AVG_TASK_DURATION_SECONDS} seconds\")\nprint(f\"Total task time: {total_task_time_seconds} seconds ({total_task_time_seconds/60:.1f} minutes)\")\nprint(f\"Target completion: {TARGET_COMPLETION_MINUTES} minutes ({target_time_seconds} seconds)\")\nprint(f\"Minimum cores required: {required_cores}\")\n\n# SOLUTION 3.2b: Add overhead for Spark driver, executors startup, etc.\n# Rule of thumb: Add 20% overhead\nOVERHEAD_FACTOR = 1.2\ncores_with_overhead = math.ceil(required_cores * OVERHEAD_FACTOR)\n\nprint(f\"\\nWith 20% overhead: {cores_with_overhead} cores\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.3: Instance Type Selection\n### AWS Instance Comparison\n| Instance | vCPUs | Memory | DBU/hr | Use Case |\n|----------|-------|--------|--------|----------|\n| m5.xlarge | 4 | 16 GB | 0.75 | General purpose |\n| m5.2xlarge | 8 | 32 GB | 1.5 | General purpose |\n| c5.2xlarge | 8 | 16 GB | 1.0 | CPU-intensive |\n| r5.2xlarge | 8 | 64 GB | 2.0 | Memory-intensive |\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# Workload characteristics assessment\n# Score 1-5 for each dimension\n\n# SOLUTION 3.3: Rate the NEMWEB workload\n\n# HTTP parsing, CSV processing - moderate CPU work\ncpu_intensity = 3\n\n# DataFrame operations, no large aggregations or wide tables\n# NEMWEB data is relatively narrow (12 columns)\nmemory_intensity = 2\n\n# Network calls to NEMWEB HTTP API - significant I/O wait\nio_intensity = 4\n\nprint(\"NEMWEB Workload Profile:\")\nprint(f\"  CPU intensity:    {cpu_intensity}/5 (CSV parsing, transforms)\")\nprint(f\"  Memory intensity: {memory_intensity}/5 (narrow tables, simple aggregations)\")\nprint(f\"  I/O intensity:    {io_intensity}/5 (HTTP fetching from NEMWEB)\")\n\n# Decision matrix\ndef recommend_instance_type(cpu: int, memory: int, io: int) -> str:\n    \"\"\"Recommend instance type based on workload characteristics.\"\"\"\n    if memory >= 4:\n        return \"r5.xlarge (memory-optimized) - Large aggregations/wide tables\"\n    elif cpu >= 4:\n        return \"c5.xlarge (CPU-optimized) - Heavy computation\"\n    else:\n        return \"m5.xlarge (general purpose) - Balanced workload\"\n\nrecommendation = recommend_instance_type(cpu_intensity, memory_intensity, io_intensity)\nprint(f\"\\nRecommended instance: {recommendation}\")\n\nprint(\"\\nRationale:\")\nprint(\"  - NEMWEB workload is I/O bound (waiting for HTTP responses)\")\nprint(\"  - Memory needs are modest (narrow tables)\")\nprint(\"  - General purpose instances provide best cost/performance\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.4: Autoscaling Configuration\n### Common Autoscaling Mistakes\n1. **Too wide**: min=1, max=32 allows runaway costs\n2. **Too narrow**: min=max=8 prevents optimization\n3. **Wrong baseline**: min too low causes slow startup\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# Workload patterns (from analysis)\nTYPICAL_LOAD_CORES = 4   # Daily incremental processing\nPEAK_LOAD_CORES = 8      # Historical backfill or catch-up scenarios\n\n# SOLUTION 3.4: Set autoscaling bounds\n# Rules:\n# - min_workers: Handle typical load with ~70% utilization\n# - max_workers: Handle peak load without exceeding budget\n# - Always round up to whole workers\n\nCORES_PER_WORKER = 4  # For m5.xlarge\n\n# min_workers should handle typical load at 70% utilization\n# If typical needs 4 cores at 100%, at 70% we need 4/0.7 â‰ˆ 6 cores\n# But we also don't want to over-provision for small loads\nmin_workers = math.ceil(TYPICAL_LOAD_CORES / CORES_PER_WORKER)\n\n# max_workers should handle peak load\nmax_workers = math.ceil(PEAK_LOAD_CORES / CORES_PER_WORKER)\n\n# Ensure min <= max\nmax_workers = max(max_workers, min_workers)\n\nprint(f\"Instance type: m5.xlarge ({CORES_PER_WORKER} cores each)\")\nprint(f\"Typical load: {TYPICAL_LOAD_CORES} cores\")\nprint(f\"Peak load: {PEAK_LOAD_CORES} cores\")\nprint(f\"\\nAutoscaling configuration:\")\nprint(f\"  min_workers: {min_workers}\")\nprint(f\"  max_workers: {max_workers}\")\nprint(f\"  Core range: {min_workers * CORES_PER_WORKER} - {max_workers * CORES_PER_WORKER}\")\n\nprint(\"\\nRationale:\")\nprint(f\"  - min={min_workers}: Handles daily incremental without scale-up delay\")\nprint(f\"  - max={max_workers}: Caps peak usage, prevents runaway costs\")\nprint(f\"  - Narrow range (1-2 workers) = predictable costs\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.5: Cost Estimation\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\n# Pricing (example - varies by cloud and commitment)\nDBU_RATE_JOBS = 0.15        # $/DBU for Jobs compute\nDBU_RATE_INTERACTIVE = 0.55  # $/DBU for All-Purpose compute\nDBU_PER_HOUR_M5_XLARGE = 0.75\n\n# Usage patterns\nRUNS_PER_DAY = 24           # Hourly incremental\nAVG_RUN_DURATION_HOURS = 0.1  # 6 minutes\nWORKERS_TYPICAL = min_workers  # Use calculated min_workers\n\n# SOLUTION 3.5a: Calculate daily DBU consumption\n# Formula: workers Ã— DBU_per_hour Ã— run_duration Ã— runs_per_day\n\ndaily_dbus = WORKERS_TYPICAL * DBU_PER_HOUR_M5_XLARGE * AVG_RUN_DURATION_HOURS * RUNS_PER_DAY\nmonthly_dbus = daily_dbus * 30\n\nprint(\"Usage Pattern:\")\nprint(f\"  Runs per day: {RUNS_PER_DAY}\")\nprint(f\"  Avg run duration: {AVG_RUN_DURATION_HOURS * 60:.0f} minutes\")\nprint(f\"  Typical workers: {WORKERS_TYPICAL}\")\nprint(f\"  DBU rate per worker: {DBU_PER_HOUR_M5_XLARGE}/hour\")\n\nprint(f\"\\nDBU Consumption:\")\nprint(f\"  Daily DBUs: {daily_dbus:.1f}\")\nprint(f\"  Monthly DBUs: {monthly_dbus:.1f}\")\n\n# SOLUTION 3.5b: Calculate monthly cost\nmonthly_cost_jobs = monthly_dbus * DBU_RATE_JOBS\nmonthly_cost_interactive = monthly_dbus * DBU_RATE_INTERACTIVE\n\nprint(f\"\\nMonthly Cost Estimate:\")\nprint(f\"  Jobs compute (${DBU_RATE_JOBS}/DBU):        ${monthly_cost_jobs:.2f}\")\nprint(f\"  Interactive (${DBU_RATE_INTERACTIVE}/DBU): ${monthly_cost_interactive:.2f}\")\n\nprint(f\"\\nðŸ’¡ Jobs compute saves ${monthly_cost_interactive - monthly_cost_jobs:.2f}/month ({(1 - DBU_RATE_JOBS/DBU_RATE_INTERACTIVE)*100:.0f}% savings)\")\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Solution 3.6: Final Configuration\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nimport json\n\ncluster_config = {\n    \"cluster_name\": \"nemweb-pipeline-prod\",\n    \"spark_version\": \"15.4.x-scala2.12\",  # DBR 15.4 for Python Data Source API\n\n    # SOLUTION 3.6: Completed configuration\n    \"node_type_id\": \"m5.xlarge\",           # General purpose - matches workload profile\n    \"driver_node_type_id\": \"m5.xlarge\",    # Same as worker for simplicity\n\n    \"autoscale\": {\n        \"min_workers\": min_workers,         # From Part 4\n        \"max_workers\": max_workers,         # From Part 4\n    },\n\n    # Autotermination for cost control\n    \"autotermination_minutes\": 20,\n\n    # Spark configuration\n    \"spark_conf\": {\n        # Optimize for workload\n        \"spark.sql.shuffle.partitions\": \"auto\",\n        \"spark.databricks.adaptive.autoOptimizeShuffle.enabled\": \"true\",\n        # Connection pooling for HTTP-heavy workload\n        \"spark.databricks.http.connectionTimeout\": \"60s\",\n    },\n\n    # Tags for cost tracking\n    \"custom_tags\": {\n        \"project\": \"nemweb-pipeline\",\n        \"environment\": \"production\",\n        \"cost_center\": \"data-engineering\"\n    }\n}\n\nprint(\"=\" * 60)\nprint(\"FINAL CLUSTER CONFIGURATION\")\nprint(\"=\" * 60)\nprint(json.dumps(cluster_config, indent=2))\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Validation Checklist\nBefore deploying to production, verify:\n- [x] Instance type matches workload profile (CPU/memory/IO) â†’ **m5.xlarge (general purpose)**\n- [x] Min workers handle typical load at 70% utilization â†’ **1 worker = 4 cores**\n- [x] Max workers handle peak load within budget â†’ **2 workers = 8 cores**\n- [x] Autotermination configured to prevent idle costs â†’ **20 minutes**\n- [x] Spark shuffle partitions set appropriately â†’ **auto**\n- [x] Cost tags configured for chargeback â†’ **project, environment, cost_center**\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Summary\n### NEMWEB Pipeline Sizing Results\n| Parameter | Value | Rationale |\n|-----------|-------|-----------|\n| Instance type | m5.xlarge | I/O bound workload, general purpose best |\n| Min workers | 1 | Handles daily incremental |\n| Max workers | 2 | Caps peak backfill scenarios |\n| Monthly DBUs | ~54 | Based on 24 runs/day Ã— 6 min each |\n| Monthly cost | ~$8 (Jobs) | Using Jobs compute pricing |\n### Key Sizing Methodology\n1. **Measure first**: Run test workload, capture Spark UI metrics\n2. **Calculate cores**: total_task_time / target_duration Ã— 1.2 (overhead)\n3. **Select instance**: Match CPU/memory/IO profile to instance family\n4. **Set autoscaling**: Based on typical vs. peak patterns\n5. **Estimate costs**: DBUs Ã— rate Ã— expected usage\n### Avoid These Mistakes\n- Intuition-based sizing without metrics\n- Memory-optimized instances for CPU-bound work\n- min=1, max=32 autoscaling (too wide)\n- Forgetting driver sizing for large collects\n- Not setting autotermination\n",
   "metadata": {}
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "/Workspace/Users/david.okeeffe@databricks.com/.bundle/nemweb-lab/dev/files/databricks-nemweb-lab/artifacts/nemweb_datasource-2.10.7-py3-none-any.whl"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03a_cluster_sizing_solution",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 4
}